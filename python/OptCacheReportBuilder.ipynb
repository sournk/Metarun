{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OptCache Report Builder\n",
    "\n",
    "Этот скрипт загружает данные оптимизации из CSV файлов и выводит топ 5 результатов по убыванию custom_fitness и profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rule = {\n",
    "    'fields': {\n",
    "        'profit': {\n",
    "            'enabled_headmap': True,\n",
    "            'enabled_report': False,\n",
    "            'range': (0.01, float('inf')),\n",
    "            'color_ranges': []\n",
    "        },\n",
    "        'trades_per_30_days': {\n",
    "            'enabled_headmap': True,\n",
    "            'enabled_report': False,\n",
    "            'range': (0.5, float('inf')),\n",
    "            'color_ranges': []\n",
    "        },\n",
    "        'profit_per_30_days_percent': {\n",
    "            'enabled_headmap': False,\n",
    "            'enabled_report': True,\n",
    "            'range': (0.005, float('inf')),\n",
    "            'color_ranges': [\n",
    "                {'range': (-float('inf'), 0.010), 'color': 'pink'},\n",
    "                {'range': (0.010, 0.020), 'color': 'moccasin'},\n",
    "                {'range': (0.020, float('inf')), 'color': 'lightgreen'}\n",
    "            ]\n",
    "        },\n",
    "        'profit_per_365_days_percent': {\n",
    "            'enabled_headmap': True,\n",
    "            'enabled_report': False,\n",
    "            'range': (0.05, float('inf')),\n",
    "            'color_ranges': [\n",
    "                {'range': (-float('inf'), 0.050), 'color': 'pink'},\n",
    "                {'range': (0.050, 0.070), 'color': 'moccasin'},\n",
    "                {'range': (0.070, 0.100), 'color': '#C5E8B7'},\n",
    "                {'range': (0.100, 0.150), 'color': '#ABE098'},\n",
    "                {'range': (0.150, 0.200), 'color': '#83D475'},\n",
    "                {'range': (0.200, 0.250), 'color': '#57C84D'},\n",
    "                {'range': (0.250, float('inf')), 'color': '#2EB62C'}\n",
    "            ]\n",
    "        },\n",
    "        'calmar': {\n",
    "            'enabled_headmap': True,\n",
    "            'enabled_report': False,\n",
    "            'range': (1.5, float('inf')),\n",
    "            'color_ranges': [\n",
    "                {'range': (1.0, 1.5), 'color': 'moccasin'},\n",
    "                {'range': (1.5, float('inf')), 'color': 'lightgreen'}\n",
    "            ]\n",
    "        },\n",
    "        'win_rate': {\n",
    "            'enabled_headmap': False,\n",
    "            'enabled_report': False,\n",
    "            'range': (0.0, float('inf')),\n",
    "            'color_ranges': [\n",
    "                {'range': (50.0, float('inf')), 'color': 'lightgreen'}\n",
    "            ]\n",
    "        },\n",
    "        'custom_fitness': {\n",
    "            'enabled_headmap': True,\n",
    "            'enabled_report': False,\n",
    "            'range': (0.75, float('inf')),\n",
    "            'color_ranges': [\n",
    "                {'range': (0.00, 0.75), 'color': 'pink'},\n",
    "                {'range': (0.76, 0.90), 'color': 'moccasin'},\n",
    "                {'range': (0.90, float('inf')), 'color': 'lightgreen'}\n",
    "            ]\n",
    "        },\n",
    "        'reldrawdownpercnt_e': {\n",
    "            'enabled_headmap': True,\n",
    "            'enabled_report': False,\n",
    "            'range': (0, 15),\n",
    "            'color_ranges': [\n",
    "                {'range': (0.00, 5.0),  'color': 'lightgreen'},\n",
    "                {'range': (5.00, 15.0), 'color': 'moccasin'},\n",
    "                {'range': (15.0, float('inf')), 'color': 'pink'}\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    'max_runs_count': 100,\n",
    "    'sort_by': ['sector', 'symbol', 'rank_score'],\n",
    "    'sort_dir': [True, True, False]\n",
    "}\n",
    "\n",
    "# Scoring configuration for rank_score calculation\n",
    "# Formula: rank_score = R² × norm(Calmar) × WeightedSum × 100\n",
    "# Where WeightedSum = Σ(w_i × norm(m_i)) / Σw_i\n",
    "scoring_config = {\n",
    "    # Weights for weighted sum (any numbers, normalized automatically)\n",
    "    'weights': {\n",
    "        'sharpe_ratio': 3,\n",
    "        'recovery_factor': 2,\n",
    "        'win_rate': 2,\n",
    "        'profit_factor': 1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadHeaderFromFileToDF(optcache_filename: str) -> pd.DataFrame:\n",
    "    header_file = Path(f'{optcache_filename}.Header.csv')\n",
    "\n",
    "    if not header_file.exists():\n",
    "        print(f\"File {header_file} do not exist\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    header_df = pd.read_csv(header_file, sep=';', encoding='utf-16')\n",
    "    header_df['days'] = (pd.to_datetime(header_df['date_to']) - pd.to_datetime(header_df['date_from'])).dt.days\n",
    "    header_df['filename'] = optcache_filename\n",
    "\n",
    "    return header_df\n",
    "\n",
    "def ClassifySymbol(symbol: str) -> str:\n",
    "    \"\"\"Classify financial symbol into category using local dictionaries and patterns\"\"\"\n",
    "    \n",
    "    symbol_upper = symbol.upper()\n",
    "    \n",
    "    # Known commodities\n",
    "    commodities = {\n",
    "        'GOLD', 'SILVER', 'COPPER', 'ALUMINIUM', 'ALUMINUM', 'PALLADIUM', 'PLATINUM',\n",
    "        'BRENT', 'WTI', 'CRUDE', 'NGAS', 'NATGAS',\n",
    "        'WHEAT', 'CORN', 'SOYBEAN', 'SUGAR', 'COFFEE', 'COCOA', 'COTTON',\n",
    "        'XAUUSD', 'XAGUSD', 'XTIUSD'\n",
    "    }\n",
    "    \n",
    "    # Known crypto prefixes\n",
    "    crypto_prefixes = {'BTC', 'ETH', 'LTC', 'XRP', 'BCH', 'ADA', 'DOT', 'LINK', 'XLM', 'DOGE', 'MATIC', 'SOL', 'AVAX'}\n",
    "    \n",
    "    # Check exact match for commodities\n",
    "    if symbol_upper in commodities:\n",
    "        return 'Commodities'\n",
    "    \n",
    "    # Check crypto (BTCUSD, ETHUSD, etc)\n",
    "    for prefix in crypto_prefixes:\n",
    "        if symbol_upper.startswith(prefix):\n",
    "            return 'Crypto'\n",
    "    \n",
    "    # Check indices (contain numbers like 50, 100, 500, 2000, etc)\n",
    "    indices_keywords = ['SP', 'NAS', 'DOW', 'DAX', 'FTSE', 'NIKKEI', 'CHINA50', 'RUSSELL', \n",
    "                        'STOXX50', 'DXY', 'HK50', 'UK100', 'US500', 'USTEC']\n",
    "    if symbol_upper in indices_keywords:\n",
    "        return 'Indices'\n",
    "    \n",
    "    # Check Forex (6 chars, 3 currency codes)\n",
    "    if len(symbol_upper) == 6 and symbol_upper.isalpha():\n",
    "        currency_codes = {'USD', 'EUR', 'GBP', 'JPY', 'AUD', 'NZD', 'CAD', 'CHF', 'CNY', 'HKD', 'SGD'}\n",
    "        first_part = symbol_upper[:3]\n",
    "        second_part = symbol_upper[3:]\n",
    "        if first_part in currency_codes and second_part in currency_codes:\n",
    "            return 'Forex'\n",
    "    \n",
    "    # If nothing matched, return Other\n",
    "    return 'Other'\n",
    "\n",
    "def GroupSymbolsByCategory(symbols: list) -> dict:\n",
    "    \"\"\"Group symbols by their categories\"\"\"\n",
    "    \n",
    "    categories = {\n",
    "        'Commodities': [],\n",
    "        'Indices': [],\n",
    "        'Crypto': [],\n",
    "        'Stocks': [],\n",
    "        'Forex': [],\n",
    "        'Other': []\n",
    "    }\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        category = ClassifySymbol(symbol)\n",
    "        categories[category].append(symbol)\n",
    "    \n",
    "    # Remove empty categories and sort symbols within each category\n",
    "    return {cat: sorted(syms) for cat, syms in categories.items() if syms}\n",
    "\n",
    "def BuildHeaderReport(header_df: pd.DataFrame, data_df: pd.DataFrame) -> list[str]:\n",
    "    if header_df.empty:\n",
    "        return []\n",
    "\n",
    "    row = header_df.iloc[0]\n",
    "\n",
    "    # Format dates as YYYY-MM-DD\n",
    "    date_from = pd.to_datetime(row[\"date_from\"]).strftime(\"%Y-%m-%d\")\n",
    "    date_to = pd.to_datetime(row[\"date_to\"]).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    symbols = list(map(str, pd.unique(data_df['symbol'])))\n",
    "    grouped_symbols = GroupSymbolsByCategory(symbols)\n",
    "    \n",
    "    report = [\n",
    "        f'## Backtest Optimization for {header_df[\"expert_name\"].iloc[0]} / {len(symbols)} sym',\n",
    "        f'<table>',\n",
    "        f'    <tr>',\n",
    "        f'        <td style=\"vertical-align: top\"> ',\n",
    "        f'            <b>Bot:</b> {row[\"expert_name\"]} <br>',\n",
    "        f'            <b>Interval:</b> [{date_from}; {date_to})<br>',\n",
    "        f'            <b>Duration:</b> {row[\"days\"]} days',\n",
    "        f'        </td>',\n",
    "        f'        <td style=\"vertical-align: top\"> ',\n",
    "        f'            <b>Server:</b> {row[\"server\"]}<br>',\n",
    "        f'            <b>Deposit:</b> {row[\"trade_deposit\"]}<br>',\n",
    "        f'            <b>Leverage:</b> 100',\n",
    "        f'        </td>',\n",
    "        f'    </tr>',\n",
    "        f'    <tr>',\n",
    "        f'        <td colspan=2>',\n",
    "    ]\n",
    "\n",
    "    # Add symbols grouped by category\n",
    "    for category, syms in grouped_symbols.items():\n",
    "        report.append(f'<b>{category}:</b> {\", \".join(syms)}')\n",
    "    \n",
    "    report.append(f'        </td>')\n",
    "    report.append(f'    </tr>')\n",
    "    report.append(f'</table>')\n",
    "\n",
    "    return report    \n",
    "\n",
    "def CalculateRankScore(df: pd.DataFrame, config: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate rank_score for each row in DataFrame.\n",
    "    \n",
    "    Formula: rank_score = R² × norm(Calmar) × WeightedSum × 100\n",
    "    \n",
    "    Where:\n",
    "    - R² = custom_fitness (already in [0, 1])\n",
    "    - norm(Calmar) = Min-Max normalized calmar ratio\n",
    "    - WeightedSum = Σ(w_i × norm(m_i)) / Σw_i\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with optimization results\n",
    "        config: Scoring configuration with weights\n",
    "    \n",
    "    Returns:\n",
    "        Series with rank_score values\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "    \n",
    "    # Min-Max normalization helper\n",
    "    def min_max_norm(series):\n",
    "        min_val = series.min()\n",
    "        max_val = series.max()\n",
    "        if max_val == min_val:\n",
    "            return pd.Series([1.0] * len(series), index=series.index)\n",
    "        return (series - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Get R² (custom_fitness) - already in [0, 1]\n",
    "    r2 = df['custom_fitness'].clip(0, 1)\n",
    "    \n",
    "    # Normalize Calmar\n",
    "    calmar_norm = min_max_norm(df['calmar'])\n",
    "    \n",
    "    # Calculate weighted sum of other metrics\n",
    "    weights = config.get('weights', {})\n",
    "    total_weight = sum(weights.values())\n",
    "    \n",
    "    if total_weight == 0:\n",
    "        weighted_sum = pd.Series([1.0] * len(df), index=df.index)\n",
    "    else:\n",
    "        weighted_sum = pd.Series([0.0] * len(df), index=df.index)\n",
    "        for metric, weight in weights.items():\n",
    "            if metric in df.columns:\n",
    "                norm_metric = min_max_norm(df[metric])\n",
    "                weighted_sum += weight * norm_metric\n",
    "        weighted_sum = weighted_sum / total_weight\n",
    "    \n",
    "    # Calculate final rank_score\n",
    "    return (r2 * calmar_norm * weighted_sum * 100).round(2)\n",
    "\n",
    "def BuildReportDF(optcache_filename: str, filter: dict, filter_key: str = 'enabled_headmap') -> pd.DataFrame: \n",
    "\n",
    "    header_df = LoadHeaderFromFileToDF(optcache_filename)\n",
    "    if header_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data_file = Path(f'{optcache_filename}.Data.csv')\n",
    "    if not data_file.exists():\n",
    "        print(f\"File {data_file} do not exist\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # add fields to data\n",
    "    data_df = pd.read_csv(data_file, sep=';', encoding='utf-16')\n",
    "    data_df['win_rate'] = data_df['profittrades'] / data_df['trades']\n",
    "    data_df['profit_per_30_days'] = data_df['profit'] / header_df['days'].iloc[0] * 30\n",
    "    data_df['profit_per_365_days'] = data_df['profit'] / header_df['days'].iloc[0] * 365\n",
    "    data_df['profit_per_30_days_percent'] = data_df['profit'] / header_df['days'].iloc[0] * 30 / data_df['initial_deposit']\n",
    "    data_df['profit_per_365_days_percent'] = data_df['profit'] / header_df['days'].iloc[0] * 365 / data_df['initial_deposit']\n",
    "    data_df['trades_per_30_days'] = data_df['trades'] / header_df['days'].iloc[0] * 30\n",
    "    \n",
    "    # Calmar Ratio = Annual Return % / Max Drawdown %\n",
    "    # Handle division by zero: if DD is 0, set calmar to a large value\n",
    "    data_df['calmar'] = np.where(\n",
    "        data_df['reldrawdownpercnt_e'] > 0,\n",
    "        data_df['profit_per_365_days_percent'] * 100 / data_df['reldrawdownpercnt_e'],\n",
    "        0  # Will be set to max after filtering\n",
    "    )\n",
    "   \n",
    "    data_df['filename'] = optcache_filename\n",
    "    data_df['symbol'] = header_df['symbol'].iloc[0]\n",
    "    data_df['sector'] = header_df['sector'].iloc[0] if 'sector' in header_df.columns else ClassifySymbol(header_df['symbol'].iloc[0])\n",
    "    data_df['expert_name'] = header_df['expert_name'].iloc[0]\n",
    "    data_df['date_from'] = header_df['date_from'].iloc[0]\n",
    "    data_df['date_to'] = header_df['date_to'].iloc[0]\n",
    "    data_df['days'] = (pd.to_datetime(header_df['date_to'].iloc[0]) - pd.to_datetime(header_df['date_from'].iloc[0])).days\n",
    "    data_df['months'] = (pd.to_datetime(header_df['date_to'].iloc[0]) - pd.to_datetime(header_df['date_from'].iloc[0])).days // 30\n",
    "    data_df['period'] = header_df['period'].iloc[0]\n",
    "    data_df['trade_deposit'] = header_df['trade_deposit'].iloc[0]\n",
    "    data_df['trade_currency'] = header_df['trade_currency'].iloc[0]\n",
    "    data_df['trade_leverage'] = header_df['trade_leverage'].iloc[0]\n",
    "    data_df['server'] = header_df['server'].iloc[0]\n",
    "    data_df['ticks_mode'] = header_df['ticks_mode'].iloc[0]\n",
    "    data_df['rank_score'] = CalculateRankScore(data_df, scoring_config)\n",
    "\n",
    "    data_df.fillna(0, inplace=True)\n",
    "\n",
    "    # filter data\n",
    "    report_data = data_df.copy()\n",
    "    for column, rule in filter.get('fields', {}).items():\n",
    "        if not rule.get(filter_key, True):\n",
    "            continue\n",
    "        if not rule.get('range'):\n",
    "            continue\n",
    "        min_val, max_val = rule['range']\n",
    "        report_data = report_data[(report_data[column] >= min_val) & (report_data[column] <= max_val)]\n",
    "\n",
    "    report_data = report_data.sort_values(filter_rule.get('sort_by', []), ascending=filter_rule.get(\"sort_dir\", []))\n",
    "    if 'max_runs_count' in filter:\n",
    "        report_data = report_data.head(filter.get('max_runs_count'))\n",
    "\n",
    "    return report_data\n",
    "\n",
    "def CreateSetFile(optcache_filename: str, pass_number: int, output_dir: str = None, \n",
    "                  server: str = None, timestamp: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Create a .set file from optimization data for a specific pass.\n",
    "    \n",
    "    Args:\n",
    "        optcache_filename: Path to the .opt file\n",
    "        pass_number: Pass number to extract parameters from\n",
    "        output_dir: Output directory for .set file (default: same as opt file)\n",
    "        server: Server name for filename\n",
    "        timestamp: Timestamp string for filename (YYYYMMDD_HHMMSS)\n",
    "    \n",
    "    Returns:\n",
    "        Path to created .set file or empty string if failed\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load header to get expert name and symbol\n",
    "    header_df = LoadHeaderFromFileToDF(optcache_filename)\n",
    "    if header_df.empty:\n",
    "        print(f\"Cannot load header from {optcache_filename}\")\n",
    "        return \"\"\n",
    "    \n",
    "    expert_name = header_df['expert_name'].iloc[0]\n",
    "    symbol = header_df['symbol'].iloc[0]\n",
    "    \n",
    "    # Load data to find the specific pass\n",
    "    data_file = Path(f'{optcache_filename}.Data.csv')\n",
    "    if not data_file.exists():\n",
    "        print(f\"File {data_file} does not exist\")\n",
    "        return \"\"\n",
    "    \n",
    "    data_df = pd.read_csv(data_file, sep=';', encoding='utf-16')\n",
    "    \n",
    "    # Find the pass\n",
    "    pass_data = data_df[data_df['Pass'] == pass_number]\n",
    "    if pass_data.empty:\n",
    "        print(f\"Pass {pass_number} not found in {data_file}\")\n",
    "        return \"\"\n",
    "    \n",
    "    # Get parameter columns - all columns after 'avgconloosers'\n",
    "    all_columns = list(data_df.columns)\n",
    "    try:\n",
    "        # Find the index of the last standard MetaTrader field\n",
    "        last_standard_field_idx = all_columns.index('avgconloosers')\n",
    "        # All columns after this are optimization parameters\n",
    "        param_columns = all_columns[last_standard_field_idx + 1:]\n",
    "    except ValueError:\n",
    "        # If 'avgconloosers' not found, fall back to 'Inp_' prefix\n",
    "        param_columns = [col for col in all_columns if col.startswith('Inp_')]\n",
    "    \n",
    "    # Filter out unnamed columns and empty column names\n",
    "    param_columns = [col for col in param_columns if not col.startswith('Unnamed:') and col.strip() != '']\n",
    "    \n",
    "    if not param_columns:\n",
    "        print(f\"No input parameters found (columns after 'avgconloosers')\")\n",
    "        return \"\"\n",
    "    \n",
    "    # Create .set file content\n",
    "    set_content = [\n",
    "        \"; saved automatically on generation\",\n",
    "        \"; this file contains input parameters for testing/optimizing expert advisor\",\n",
    "        \";\"\n",
    "    ]\n",
    "    \n",
    "    # Add each parameter\n",
    "    pass_row = pass_data.iloc[0]\n",
    "    for param in param_columns:\n",
    "        value = pass_row[param]\n",
    "        \n",
    "        # Skip NaN values\n",
    "        if pd.isna(value):\n",
    "            continue\n",
    "        \n",
    "        # Determine parameter type and format value\n",
    "        if isinstance(value, (int, np.integer)):\n",
    "            set_content.append(f\"{param}={int(value)}\")\n",
    "        elif isinstance(value, (float, np.floating)):\n",
    "            set_content.append(f\"{param}={value}\")\n",
    "        else:\n",
    "            set_content.append(f\"{param}={value}\")\n",
    "    \n",
    "    # Determine output path\n",
    "    if output_dir is None:\n",
    "        output_dir = Path(optcache_filename).parent\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create .set filename: {expert_name}_{server}_{timestamp}_{symbol}_{pass_number}.set\n",
    "    set_filename = output_dir / f\"{expert_name}_{server}_{timestamp}_{symbol}_{pass_number}.set\"\n",
    "    \n",
    "    # Write .set file\n",
    "    try:\n",
    "        with open(set_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(set_content))\n",
    "        return str(set_filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing .set file: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildReportExcel(header_df: pd.DataFrame, data_df: pd.DataFrame, filter_rule: dict, \n",
    "                     all_symbols: list, output_filename: str, heatmap_df: pd.DataFrame = None,\n",
    "                     timestamp: str = None) -> str:\n",
    "    \"\"\"Build Excel report with Heatmap sheet + SmartTable (auto-filter) and color coding\n",
    "    \n",
    "    Features:\n",
    "    - Heatmap sheet with symbol overview (first sheet) - uses unfiltered data\n",
    "    - Data sheet with SmartTable and filtering/sorting\n",
    "    - Color coding for metrics (same as MD/HTML reports)\n",
    "    - Frozen header row\n",
    "    - Auto-width columns\n",
    "    - Header with report info\n",
    "    \n",
    "    Args:\n",
    "        header_df: Header DataFrame\n",
    "        data_df: DataFrame with filtered results\n",
    "        filter_rule: Filter rules dictionary\n",
    "        all_symbols: List of all symbols\n",
    "        output_filename: Output Excel filename\n",
    "        heatmap_df: DataFrame with unfiltered results for heatmap (optional, uses data_df if None)\n",
    "        timestamp: Timestamp string for set file names (YYYYMMDD_HHMMSS)\n",
    "    \n",
    "    Returns:\n",
    "        Path to saved Excel file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use heatmap_df for heatmap if provided, otherwise use data_df\n",
    "    heatmap_source_df = heatmap_df if heatmap_df is not None else data_df\n",
    "    \n",
    "    def get_fill_color(field_name, value):\n",
    "        \"\"\"Get fill color for a value based on filter_rule color_ranges\"\"\"\n",
    "        rule = filter_rule.get('fields', {}).get(field_name, {})\n",
    "        color_ranges = rule.get('color_ranges', [])\n",
    "        for cr in color_ranges:\n",
    "            if value >= cr['range'][0] and value < cr['range'][1]:\n",
    "                color = cr['color']\n",
    "                # Convert color names/hex to RGB for openpyxl\n",
    "                color_map = {\n",
    "                    'pink': 'FFB6C1',\n",
    "                    'moccasin': 'FFE4B5',\n",
    "                    'lightgreen': '90EE90',\n",
    "                    '#C5E8B7': 'C5E8B7',\n",
    "                    '#ABE098': 'ABE098',\n",
    "                    '#83D475': '83D475',\n",
    "                    '#57C84D': '57C84D',\n",
    "                    '#2EB62C': '2EB62C',\n",
    "                }\n",
    "                return color_map.get(color, color.replace('#', '') if color.startswith('#') else None)\n",
    "        return None\n",
    "    \n",
    "    # Calculate max calmar from heatmap source for gradient scaling\n",
    "    max_calmar_for_gradient = 1.0\n",
    "    if not heatmap_source_df.empty:\n",
    "        # Get best calmar per symbol\n",
    "        best_calmars = []\n",
    "        for symbol in all_symbols:\n",
    "            symbol_df = heatmap_source_df[heatmap_source_df['symbol'] == symbol]\n",
    "            if not symbol_df.empty:\n",
    "                best_calmars.append(symbol_df['calmar'].max())\n",
    "        if best_calmars:\n",
    "            max_calmar_for_gradient = max(max_calmar_for_gradient, max(best_calmars))\n",
    "    \n",
    "    def get_calmar_fill(calmar, count, filtered_count):\n",
    "        \"\"\"Get fill color for heatmap cell based on calmar value with dynamic gradient\n",
    "        \n",
    "        Colors:\n",
    "        - Gray: No data at all (count=0)\n",
    "        - Pink: Best Calmar <= 1\n",
    "        - Yellow (moccasin): Calmar > 1, but no results after filtering (filtered_count=0)\n",
    "        - Green gradient: Calmar > 1 AND has results after filtering\n",
    "        \"\"\"\n",
    "        if count == 0:\n",
    "            return 'D3D3D3'  # Gray - no data\n",
    "        if calmar <= 1.0:\n",
    "            return 'FFB6C1'  # Pink - Calmar <= 1\n",
    "        if filtered_count == 0:\n",
    "            return 'FFE4B5'  # Yellow (moccasin) - Calmar > 1 but filtered out\n",
    "        \n",
    "        # Gradient green for calmar > 1 with filtered results\n",
    "        # Scale from 1 to max_calmar_for_gradient\n",
    "        # Colors from light green to dark green\n",
    "        green_colors = ['C5E8B7', 'ABE098', '83D475', '57C84D', '2EB62C']\n",
    "        \n",
    "        if max_calmar_for_gradient <= 1.0:\n",
    "            return green_colors[-1]  # Best green if no spread\n",
    "        \n",
    "        # Normalize calmar to [0, 1] range where 1.0 -> 0, max_calmar -> 1\n",
    "        t = (calmar - 1.0) / (max_calmar_for_gradient - 1.0)\n",
    "        t = min(max(t, 0), 1)  # Clamp to [0, 1]\n",
    "        \n",
    "        # Map to color index\n",
    "        idx = int(t * (len(green_colors) - 1))\n",
    "        idx = min(idx, len(green_colors) - 1)\n",
    "        \n",
    "        return green_colors[idx]\n",
    "    \n",
    "    # Get header info\n",
    "    hdr_row = header_df.iloc[0]\n",
    "    date_from = pd.to_datetime(hdr_row[\"date_from\"]).strftime(\"%Y-%m-%d\")\n",
    "    date_to = pd.to_datetime(hdr_row[\"date_to\"]).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Create workbook\n",
    "    wb = Workbook()\n",
    "    \n",
    "    # ==================== HEATMAP SHEET (First) ====================\n",
    "    ws_heatmap = wb.active\n",
    "    ws_heatmap.title = \"Heatmap\"\n",
    "    \n",
    "    # Collect symbol data for heatmap (using unfiltered data)\n",
    "    symbols_data = []\n",
    "    for symbol in sorted(all_symbols):\n",
    "        symbol_df = heatmap_source_df[heatmap_source_df['symbol'] == symbol] if not heatmap_source_df.empty else pd.DataFrame()\n",
    "        count = len(symbol_df)\n",
    "        \n",
    "        # Count filtered results for this symbol\n",
    "        filtered_symbol_df = data_df[data_df['symbol'] == symbol] if not data_df.empty else pd.DataFrame()\n",
    "        filtered_count = len(filtered_symbol_df)\n",
    "        \n",
    "        if count > 0:\n",
    "            # Get best row by calmar (highest calmar = best)\n",
    "            best_row = symbol_df.loc[symbol_df['calmar'].idxmax()]\n",
    "            best_calmar = best_row['calmar']\n",
    "            best_profit_pct = best_row['profit_per_365_days_percent'] * 100\n",
    "            best_dd = best_row['reldrawdownpercnt_e']\n",
    "            best_cc = best_row['custom_fitness']\n",
    "            sector = best_row['sector'] if 'sector' in best_row else ClassifySymbol(symbol)\n",
    "        else:\n",
    "            best_calmar = 0\n",
    "            best_profit_pct = 0\n",
    "            best_dd = 0\n",
    "            best_cc = 0\n",
    "            sector = ClassifySymbol(symbol)\n",
    "        \n",
    "        symbols_data.append({\n",
    "            'symbol': symbol,\n",
    "            'count': count,\n",
    "            'filtered_count': filtered_count,\n",
    "            'calmar': best_calmar,\n",
    "            'profit_pct': best_profit_pct,\n",
    "            'dd': best_dd,\n",
    "            'cc': best_cc,\n",
    "            'sector': sector\n",
    "        })\n",
    "    \n",
    "    # Sort by sector then symbol\n",
    "    symbols_data.sort(key=lambda x: (x['sector'], x['symbol']))\n",
    "    \n",
    "    # Build filter description string\n",
    "    filter_parts = []\n",
    "    field_names = {\n",
    "        'profit': 'Profit',\n",
    "        'trades_per_30_days': 'Trades/mo',\n",
    "        'profit_per_30_days_percent': '%/30d',\n",
    "        'profit_per_365_days_percent': '%/yr',\n",
    "        'calmar': 'Calmar',\n",
    "        'win_rate': 'WR%',\n",
    "        'custom_fitness': 'CC',\n",
    "        'reldrawdownpercnt_e': 'DD%'\n",
    "    }\n",
    "    for field, rule in filter_rule.get('fields', {}).items():\n",
    "        if rule.get('enabled_headmap', False):\n",
    "            min_val, max_val = rule.get('range', (0, float('inf')))\n",
    "            field_label = field_names.get(field, field)\n",
    "            if max_val == float('inf'):\n",
    "                filter_parts.append(f\"{field_label}≥{min_val}\")\n",
    "            elif min_val == -float('inf') or min_val == 0:\n",
    "                filter_parts.append(f\"{field_label}≤{max_val}\")\n",
    "            else:\n",
    "                filter_parts.append(f\"{field_label}:[{min_val};{max_val}]\")\n",
    "    filter_str = \"Filters: \" + \", \".join(filter_parts) if filter_parts else \"Filters: None\"\n",
    "    \n",
    "    # Heatmap header\n",
    "    ws_heatmap['A1'] = f\"Heatmap: {hdr_row['expert_name']}\"\n",
    "    ws_heatmap['A1'].font = Font(bold=True, size=16)\n",
    "    ws_heatmap.merge_cells('A1:F1')\n",
    "    \n",
    "    ws_heatmap['A2'] = f\"{date_from} → {date_to} | {hdr_row['server']} | {len(all_symbols)} symbols | {len(data_df)} results\"\n",
    "    ws_heatmap['A2'].font = Font(size=11, color='666666')\n",
    "    ws_heatmap.merge_cells('A2:F2')\n",
    "    \n",
    "    ws_heatmap['A3'] = filter_str\n",
    "    ws_heatmap['A3'].font = Font(size=10, italic=True, color='888888')\n",
    "    ws_heatmap.merge_cells('A3:F3')\n",
    "    \n",
    "    # Row 4: Color legend\n",
    "    legend_items = [\n",
    "        ('D3D3D3', 'No data'),\n",
    "        ('FFB6C1', 'Calmar ≤ 1'),\n",
    "        ('FFE4B5', 'Filtered out'),\n",
    "        ('C5E8B7', 'Calmar > 1'),\n",
    "        ('2EB62C', 'Best Calmar'),\n",
    "    ]\n",
    "    legend_thin_border = Border(\n",
    "        left=Side(style='thin', color='AAAAAA'),\n",
    "        right=Side(style='thin', color='AAAAAA'),\n",
    "        top=Side(style='thin', color='AAAAAA'),\n",
    "        bottom=Side(style='thin', color='AAAAAA')\n",
    "    )\n",
    "    for col_idx, (color, label) in enumerate(legend_items, 1):\n",
    "        cell = ws_heatmap.cell(row=4, column=col_idx, value=label)\n",
    "        cell.fill = PatternFill(start_color=color, end_color=color, fill_type='solid')\n",
    "        cell.font = Font(size=9, bold=True)\n",
    "        cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "        cell.border = legend_thin_border\n",
    "    ws_heatmap.row_dimensions[4].height = 20\n",
    "    \n",
    "    # Heatmap grid settings\n",
    "    cols_per_row = 6\n",
    "    cell_width = 18\n",
    "    \n",
    "    # Set column widths\n",
    "    for col_idx in range(1, cols_per_row + 1):\n",
    "        ws_heatmap.column_dimensions[chr(ord('A') + col_idx - 1)].width = cell_width\n",
    "    \n",
    "    # Build heatmap grid\n",
    "    start_row = 6\n",
    "    for idx, data in enumerate(symbols_data):\n",
    "        row_num = start_row + (idx // cols_per_row) * 6  # 6 rows per heatmap row (symbol, CAGR, DD, Calmar, CC, gap)\n",
    "        col_num = (idx % cols_per_row) + 1\n",
    "        \n",
    "        fill_color = get_calmar_fill(data['calmar'], data['count'], data['filtered_count'])\n",
    "        cell_fill = PatternFill(start_color=fill_color, end_color=fill_color, fill_type='solid')\n",
    "        center_align = Alignment(horizontal='center', vertical='center')\n",
    "        thin_border = Border(\n",
    "            left=Side(style='thin', color='AAAAAA'),\n",
    "            right=Side(style='thin', color='AAAAAA'),\n",
    "            top=Side(style='thin', color='AAAAAA'),\n",
    "            bottom=Side(style='thin', color='AAAAAA')\n",
    "        )\n",
    "        \n",
    "        # Row 1: Symbol name (bold) - show filtered count in parentheses\n",
    "        cell1 = ws_heatmap.cell(row=row_num, column=col_num, value=f\"{data['symbol']}({data['filtered_count']})\")\n",
    "        cell1.font = Font(bold=True, size=12)\n",
    "        cell1.fill = cell_fill\n",
    "        cell1.alignment = center_align\n",
    "        cell1.border = thin_border\n",
    "        \n",
    "        # Row 2: CAGR (profit per year %)\n",
    "        cell2 = ws_heatmap.cell(row=row_num + 1, column=col_num, value=f\"CAGR: {data['profit_pct']:.1f}%\")\n",
    "        cell2.fill = cell_fill\n",
    "        cell2.alignment = center_align\n",
    "        cell2.border = thin_border\n",
    "        cell2.font = Font(size=10)\n",
    "\n",
    "        # Row 3: DD (drawdown %)\n",
    "        cell3 = ws_heatmap.cell(row=row_num + 2, column=col_num, value=f\"DD: {data['dd']:.1f}%\")\n",
    "        cell3.fill = cell_fill\n",
    "        cell3.alignment = center_align\n",
    "        cell3.border = thin_border\n",
    "        cell3.font = Font(size=10)\n",
    "\n",
    "        # Row 4: Calmar ratio\n",
    "        cell4 = ws_heatmap.cell(row=row_num + 3, column=col_num, value=f\"Calmar: {data['calmar']:.1f}\")\n",
    "        cell4.fill = cell_fill\n",
    "        cell4.alignment = center_align\n",
    "        cell4.border = thin_border\n",
    "        cell4.font = Font(size=10)\n",
    "\n",
    "        # Row 5: CC (custom criterion)\n",
    "        cell5 = ws_heatmap.cell(row=row_num + 4, column=col_num, value=f\"CC: {data['cc']:.2f}\")\n",
    "        cell5.fill = cell_fill\n",
    "        cell5.alignment = center_align\n",
    "        cell5.border = thin_border\n",
    "        cell5.font = Font(size=10)\n",
    "    \n",
    "    # Set row heights for heatmap\n",
    "    total_heatmap_rows = ((len(symbols_data) - 1) // cols_per_row + 1) * 6\n",
    "    for row in range(start_row, start_row + total_heatmap_rows):\n",
    "        ws_heatmap.row_dimensions[row].height = 18\n",
    "    \n",
    "    # ==================== DATA SHEET (Second) ====================\n",
    "    ws_data = wb.create_sheet(title=\"Data\")\n",
    "    \n",
    "    # Add header info (rows 1-3)\n",
    "    ws_data['A1'] = f\"Optimization Report: {hdr_row['expert_name']}\"\n",
    "    ws_data['A1'].font = Font(bold=True, size=14)\n",
    "    ws_data.merge_cells('A1:O1')\n",
    "    \n",
    "    ws_data['A2'] = f\"Interval: {date_from} → {date_to} | Server: {hdr_row['server']} | Deposit: {hdr_row['trade_deposit']} | Symbols: {len(all_symbols)} | Results: {len(data_df)}\"\n",
    "    ws_data['A2'].font = Font(size=10, color='666666')\n",
    "    ws_data.merge_cells('A2:O2')\n",
    "    \n",
    "    # Row 3: Filters\n",
    "    ws_data['A3'] = filter_str\n",
    "    ws_data['A3'].font = Font(size=10, italic=True, color='888888')\n",
    "    ws_data.merge_cells('A3:O3')\n",
    "    \n",
    "    # Empty row 4\n",
    "    ws_data['A4'] = \"\"\n",
    "    \n",
    "    # Define columns\n",
    "    columns = [\n",
    "        {'key': '#', 'title': '#', 'width': 6},\n",
    "        {'key': 'symbol', 'title': 'Symbol', 'width': 10},\n",
    "        {'key': 'sector', 'title': 'Sector', 'width': 12},\n",
    "        {'key': 'Pass', 'title': 'Pass', 'width': 8},\n",
    "        {'key': 'profit', 'title': 'Profit', 'width': 12},\n",
    "        {'key': 'profit_per_365_days_percent', 'title': '%/yr', 'width': 8, 'color_field': 'profit_per_365_days_percent', 'multiply': 100},\n",
    "        {'key': 'reldrawdownpercnt_e', 'title': 'DD%', 'width': 8, 'color_field': 'reldrawdownpercnt_e'},\n",
    "        {'key': 'calmar', 'title': 'Calmar', 'width': 8, 'color_field': 'calmar'},\n",
    "        {'key': 'custom_fitness', 'title': 'CC', 'width': 8, 'color_field': 'custom_fitness'},\n",
    "        {'key': 'trades_per_30_days', 'title': 'Pos/mo', 'width': 8},\n",
    "        {'key': 'win_rate', 'title': 'WR%', 'width': 8, 'multiply': 100},\n",
    "        {'key': 'profit_factor', 'title': 'PF', 'width': 8},\n",
    "        {'key': 'recovery_factor', 'title': 'RF', 'width': 8},\n",
    "        {'key': 'sharpe_ratio', 'title': 'Sharpe', 'width': 8},\n",
    "        {'key': 'rank_score', 'title': 'Rank', 'width': 8},\n",
    "        {'key': 'set_file', 'title': 'Set File', 'width': 40},\n",
    "    ]\n",
    "    \n",
    "    # Header row styles\n",
    "    header_fill = PatternFill(start_color='4A5568', end_color='4A5568', fill_type='solid')\n",
    "    header_font = Font(bold=True, color='FFFFFF')\n",
    "    header_alignment = Alignment(horizontal='center', vertical='center')\n",
    "    thin_border = Border(\n",
    "        left=Side(style='thin', color='CCCCCC'),\n",
    "        right=Side(style='thin', color='CCCCCC'),\n",
    "        top=Side(style='thin', color='CCCCCC'),\n",
    "        bottom=Side(style='thin', color='CCCCCC')\n",
    "    )\n",
    "    \n",
    "    # Write header row (row 5)\n",
    "    header_row_num = 5\n",
    "    for col_idx, col in enumerate(columns, 1):\n",
    "        cell = ws_data.cell(row=header_row_num, column=col_idx, value=col['title'])\n",
    "        cell.fill = header_fill\n",
    "        cell.font = header_font\n",
    "        cell.alignment = header_alignment\n",
    "        cell.border = thin_border\n",
    "        ws_data.column_dimensions[cell.column_letter].width = col['width']\n",
    "    \n",
    "    # Sort data\n",
    "    sorted_df = data_df.sort_values(\n",
    "        filter_rule.get('sort_by', []), \n",
    "        ascending=filter_rule.get(\"sort_dir\", [])\n",
    "    )\n",
    "    \n",
    "    # Write data rows\n",
    "    data_start_row = header_row_num + 1\n",
    "    for row_idx, (_, row_data) in enumerate(sorted_df.iterrows(), 1):\n",
    "        excel_row = data_start_row + row_idx - 1\n",
    "        \n",
    "        # Generate set file name for this row: {expert_name}_{server}_{timestamp}_{symbol}_{pass}.set\n",
    "        set_file_name = f\"{row_data['expert_name']}_{row_data['server']}_{timestamp}_{row_data['symbol']}_{int(row_data['Pass'])}.set\"\n",
    "        \n",
    "        for col_idx, col in enumerate(columns, 1):\n",
    "            # Get value\n",
    "            if col['key'] == '#':\n",
    "                value = row_idx\n",
    "            elif col['key'] == 'set_file':\n",
    "                value = set_file_name\n",
    "            else:\n",
    "                value = row_data.get(col['key'], '')\n",
    "                # Apply multiplier if specified\n",
    "                if 'multiply' in col and isinstance(value, (int, float)):\n",
    "                    value = value * col['multiply']\n",
    "            \n",
    "            # Round numeric values\n",
    "            if isinstance(value, float):\n",
    "                if col['key'] in ['profit']:\n",
    "                    value = round(value, 0)\n",
    "                elif col['key'] in ['profit_per_365_days_percent', 'win_rate']:\n",
    "                    value = round(value, 1)\n",
    "                else:\n",
    "                    value = round(value, 2)\n",
    "            \n",
    "            cell = ws_data.cell(row=excel_row, column=col_idx, value=value)\n",
    "            cell.border = thin_border\n",
    "            cell.alignment = Alignment(horizontal='center' if col_idx > 3 else 'left')\n",
    "            \n",
    "            # Apply color coding\n",
    "            if 'color_field' in col:\n",
    "                original_value = row_data.get(col['color_field'], 0)\n",
    "                fill_color = get_fill_color(col['color_field'], original_value)\n",
    "                if fill_color:\n",
    "                    cell.fill = PatternFill(start_color=fill_color, end_color=fill_color, fill_type='solid')\n",
    "    \n",
    "    # Calculate table range\n",
    "    last_row = data_start_row + len(sorted_df) - 1\n",
    "    last_col_letter = chr(ord('A') + len(columns) - 1)\n",
    "    table_range = f\"A{header_row_num}:{last_col_letter}{last_row}\"\n",
    "    \n",
    "    # Create SmartTable\n",
    "    table = Table(displayName=\"OptimizationResults\", ref=table_range)\n",
    "    \n",
    "    # Add table style (medium blue style with banded rows)\n",
    "    style = TableStyleInfo(\n",
    "        name=\"TableStyleMedium2\",\n",
    "        showFirstColumn=False,\n",
    "        showLastColumn=False,\n",
    "        showRowStripes=True,\n",
    "        showColumnStripes=False\n",
    "    )\n",
    "    table.tableStyleInfo = style\n",
    "    ws_data.add_table(table)\n",
    "    \n",
    "    # Freeze panes (freeze header row)\n",
    "    ws_data.freeze_panes = f'A{data_start_row}'\n",
    "    \n",
    "    # Save workbook\n",
    "    wb.save(output_filename)\n",
    "    \n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Сортировка и вывод топ 5 результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel report saved: HTFVWAP-MT5-Bot-2.00_Tickmill-Demo_20251213_005517.xlsx\n",
      "\n",
      "Creating .set files in set_files/...\n",
      "Created 667 .set files\n",
      "Created 667 .set files\n"
     ]
    }
   ],
   "source": [
    "dir = Path('csv')\n",
    "set_output_dir = Path('set_files')\n",
    "\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "opt_files = sorted(dir.glob(\"*.opt\"))\n",
    "if not opt_files:\n",
    "    print(f\"No .opt files found in {dir}\")\n",
    "\n",
    "# Collect all symbols from all .opt header files (before filtering)\n",
    "all_symbols = []\n",
    "for opt_file in opt_files:\n",
    "    hdr = LoadHeaderFromFileToDF(opt_file)\n",
    "    if not hdr.empty:\n",
    "        all_symbols.append(hdr['symbol'].iloc[0])\n",
    "all_symbols = sorted(set(all_symbols))\n",
    "\n",
    "# Build unfiltered dataframe for heatmap (best calmar per symbol without filtering)\n",
    "unfiltered_df = pd.DataFrame()\n",
    "for opt_file in opt_files:\n",
    "    opt_df = BuildReportDF(opt_file, {'fields': {}})  # No filters\n",
    "    if not opt_df.empty:\n",
    "        unfiltered_df = pd.concat([unfiltered_df, opt_df], ignore_index=True)\n",
    "\n",
    "# Build dataframe with heatmap filtering (for heatmap display)\n",
    "heatmap_filtered_df = pd.DataFrame()\n",
    "for opt_file in opt_files:\n",
    "    opt_df = BuildReportDF(opt_file, filter_rule, filter_key='enabled_headmap')\n",
    "    if not opt_df.empty:\n",
    "        heatmap_filtered_df = pd.concat([heatmap_filtered_df, opt_df], ignore_index=True)\n",
    "\n",
    "# Build dataframe with report filtering (for Data table and .set files)\n",
    "report_filtered_df = pd.DataFrame()\n",
    "for opt_file in opt_files:\n",
    "    opt_df = BuildReportDF(opt_file, filter_rule, filter_key='enabled_report')\n",
    "    if not opt_df.empty:\n",
    "        report_filtered_df = pd.concat([report_filtered_df, opt_df], ignore_index=True)\n",
    "\n",
    "# load header from the first .opt file\n",
    "header_df = LoadHeaderFromFileToDF(opt_files[0])\n",
    "\n",
    "# Get report parameters for filename\n",
    "expert_name = header_df['expert_name'].iloc[0] if not header_df.empty else 'Unknown'\n",
    "server = header_df['server'].iloc[0] if not header_df.empty else 'Unknown'\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Build and save Excel report with SmartTable\n",
    "# - heatmap uses heatmap_filtered_df for filtered_count calculation\n",
    "# - data table uses report_filtered_df\n",
    "excel_filename = f\"{expert_name}_{server}_{timestamp}.xlsx\"\n",
    "BuildReportExcel(header_df, report_filtered_df, filter_rule, all_symbols, excel_filename, heatmap_df=unfiltered_df, timestamp=timestamp)\n",
    "print(f\"Excel report saved: {excel_filename}\")\n",
    "\n",
    "# Create .set files for all records in the report (filtered by enabled_report)\n",
    "if not report_filtered_df.empty:\n",
    "    set_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Sort report_filtered_df the same way as in the report\n",
    "    sorted_df = report_filtered_df.sort_values(filter_rule.get('sort_by', []), ascending=filter_rule.get(\"sort_dir\", []))\n",
    "    \n",
    "    print(f\"\\nCreating .set files in {set_output_dir}/...\")\n",
    "    created_count = 0\n",
    "    \n",
    "    for idx, row in sorted_df.iterrows():\n",
    "        opt_filename = row['filename']\n",
    "        pass_num = int(row['Pass'])\n",
    "        \n",
    "        set_file = CreateSetFile(\n",
    "            opt_filename, \n",
    "            pass_num, \n",
    "            output_dir=str(set_output_dir),\n",
    "            server=server,\n",
    "            timestamp=timestamp\n",
    "        )\n",
    "        if set_file:\n",
    "            created_count += 1\n",
    "    \n",
    "    print(f\"Created {created_count} .set files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
