{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OptCache Report Builder\n",
    "\n",
    "Этот скрипт загружает данные оптимизации из CSV файлов и выводит топ 5 результатов по убыванию custom_fitness и profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filter_rule = {\n",
    "    'fields': {\n",
    "        'profit': {\n",
    "            'enabled': True,\n",
    "            'range': (0.01, float('inf')),\n",
    "            'color_ranges': []\n",
    "        },\n",
    "        'trades_per_30_days': {\n",
    "            'enabled': True,\n",
    "            'range': (0.5, float('inf')),\n",
    "            'color_ranges': []\n",
    "        },\n",
    "        'profit_per_30_days_percent': {\n",
    "            'enabled': False,\n",
    "            'range': (0.005, float('inf')),\n",
    "            'color_ranges': [\n",
    "                {'range': (-float('inf'), 0.010), 'color': 'pink'},\n",
    "                {'range': (0.010, 0.020), 'color': 'moccasin'},\n",
    "                {'range': (0.020, float('inf')), 'color': 'green'}\n",
    "            ]\n",
    "        },\n",
    "        'win_rate': {\n",
    "            'enabled': False,\n",
    "            'range': (0.0, float('inf')),\n",
    "            'color_ranges': [\n",
    "                {'range': (50.0, float('inf')), 'color': 'lightgreen'}\n",
    "            ]\n",
    "        },\n",
    "        'custom_fitness': {\n",
    "            'enabled': True,\n",
    "            'range': (0.75, float('inf')),\n",
    "            'color_ranges': [\n",
    "                {'range': (0.00, 0.75), 'color': 'pink'},\n",
    "                {'range': (0.76, 0.90), 'color': 'moccasin'},\n",
    "                {'range': (0.90, float('inf')), 'color': 'lightgreen'}\n",
    "            ]\n",
    "        },\n",
    "        'reldrawdownpercnt_e': {\n",
    "            'enabled': True,\n",
    "            'range': (0, 15),\n",
    "            'color_ranges': [\n",
    "                {'range': (0.00, 5.0),  'color': 'lightgreen'},\n",
    "                {'range': (5.00, 15.0), 'color': 'moccasin'},\n",
    "                {'range': (15.0, float('inf')), 'color': 'pink'}\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    'max_runs_count': 5,\n",
    "    'sort_by': ['profit', 'custom_fitness', 'reldrawdownpercnt_e'],\n",
    "    'sort_dir': [False, False, True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadHeaderFromFileToDF(optcache_filename: str) -> pd.DataFrame:\n",
    "    header_file = Path(f'{optcache_filename}.Header.csv')\n",
    "\n",
    "    if not header_file.exists():\n",
    "        print(f\"File {header_file} do not exist\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    header_df = pd.read_csv(header_file, sep=';', encoding='utf-16')\n",
    "    header_df['days'] = (pd.to_datetime(header_df['date_to']) - pd.to_datetime(header_df['date_from'])).dt.days\n",
    "    header_df['filename'] = optcache_filename\n",
    "\n",
    "    return header_df\n",
    "\n",
    "def ClassifySymbol(symbol: str) -> str:\n",
    "    \"\"\"Classify financial symbol into category using local dictionaries and patterns\"\"\"\n",
    "    \n",
    "    symbol_upper = symbol.upper()\n",
    "    \n",
    "    # Known commodities\n",
    "    commodities = {\n",
    "        'GOLD', 'SILVER', 'COPPER', 'ALUMINIUM', 'ALUMINUM', 'PALLADIUM', 'PLATINUM',\n",
    "        'BRENT', 'WTI', 'CRUDE', 'NGAS', 'NATGAS',\n",
    "        'WHEAT', 'CORN', 'SOYBEAN', 'SUGAR', 'COFFEE', 'COCOA', 'COTTON',\n",
    "        'XAUUSD', 'XAGUSD', 'XTIUSD'\n",
    "    }\n",
    "    \n",
    "    # Known crypto prefixes\n",
    "    crypto_prefixes = {'BTC', 'ETH', 'LTC', 'XRP', 'BCH', 'ADA', 'DOT', 'LINK', 'XLM', 'DOGE', 'MATIC', 'SOL', 'AVAX'}\n",
    "    \n",
    "    # Check exact match for commodities\n",
    "    if symbol_upper in commodities:\n",
    "        return 'Commodities'\n",
    "    \n",
    "    # Check crypto (BTCUSD, ETHUSD, etc)\n",
    "    for prefix in crypto_prefixes:\n",
    "        if symbol_upper.startswith(prefix):\n",
    "            return 'Crypto'\n",
    "    \n",
    "    # Check indices (contain numbers like 50, 100, 500, 2000, etc)\n",
    "    indices_keywords = ['SP', 'NAS', 'DOW', 'DAX', 'FTSE', 'NIKKEI', 'CHINA50', 'RUSSELL', \n",
    "                        'STOXX50', 'DXY', 'HK50', 'UK100', 'US500', 'USTEC']\n",
    "    if symbol_upper in indices_keywords:\n",
    "        return 'Indices'\n",
    "    \n",
    "    # Check Forex (6 chars, 3 currency codes)\n",
    "    if len(symbol_upper) == 6 and symbol_upper.isalpha():\n",
    "        currency_codes = {'USD', 'EUR', 'GBP', 'JPY', 'AUD', 'NZD', 'CAD', 'CHF', 'CNY', 'HKD', 'SGD'}\n",
    "        first_part = symbol_upper[:3]\n",
    "        second_part = symbol_upper[3:]\n",
    "        if first_part in currency_codes and second_part in currency_codes:\n",
    "            return 'Forex'\n",
    "    \n",
    "    # If nothing matched, return Other\n",
    "    return 'Other'\n",
    "\n",
    "def GroupSymbolsByCategory(symbols: list) -> dict:\n",
    "    \"\"\"Group symbols by their categories\"\"\"\n",
    "    \n",
    "    categories = {\n",
    "        'Commodities': [],\n",
    "        'Indices': [],\n",
    "        'Crypto': [],\n",
    "        'Stocks': [],\n",
    "        'Forex': [],\n",
    "        'Other': []\n",
    "    }\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        category = ClassifySymbol(symbol)\n",
    "        categories[category].append(symbol)\n",
    "    \n",
    "    # Remove empty categories and sort symbols within each category\n",
    "    return {cat: sorted(syms) for cat, syms in categories.items() if syms}\n",
    "\n",
    "def BuildHeaderReport(header_df: pd.DataFrame, data_df: pd.DataFrame) -> list[str]:\n",
    "    if header_df.empty:\n",
    "        return []\n",
    "\n",
    "    row = header_df.iloc[0]\n",
    "\n",
    "    # Format dates as YYYY-MM-DD\n",
    "    date_from = pd.to_datetime(row[\"date_from\"]).strftime(\"%Y-%m-%d\")\n",
    "    date_to = pd.to_datetime(row[\"date_to\"]).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    symbols = list(map(str, pd.unique(data_df['symbol'])))\n",
    "    grouped_symbols = GroupSymbolsByCategory(symbols)\n",
    "    \n",
    "    report = [\n",
    "        f'## Optimization Results for {header_df[\"expert_name\"].iloc[0]} / {len(symbols)} sym',\n",
    "        f'**Bot:** {row[\"expert_name\"]}',\n",
    "        f'**Server:** {row[\"server\"]}',\n",
    "        f'**Initial Deposit:** {row[\"trade_deposit\"]}',\n",
    "        f'**Leverage:** {row[\"trade_leverage\"]}',\n",
    "        f'**Time Interval:** [{date_from}; {date_to}) - {row[\"days\"]} days'\n",
    "    ]\n",
    "    \n",
    "    # Add symbols grouped by category\n",
    "    for category, syms in grouped_symbols.items():\n",
    "        report.append(f'**{category}:** {\", \".join(syms)}')\n",
    "\n",
    "    return report    \n",
    "\n",
    "def BuildReportDF(optcache_filename: str, filter: dict) -> pd.DataFrame: \n",
    "\n",
    "    header_df = LoadHeaderFromFileToDF(optcache_filename)\n",
    "    if header_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data_file = Path(f'{optcache_filename}.Data.csv')\n",
    "    if not data_file.exists():\n",
    "        print(f\"File {data_file} do not exist\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # add fields to data\n",
    "    data_df = pd.read_csv(data_file, sep=';', encoding='utf-16')\n",
    "    data_df['win_rate'] = data_df['profittrades'] / data_df['trades']\n",
    "    data_df['profit_per_30_days'] = data_df['profit'] / header_df['days'].iloc[0] * 30\n",
    "    data_df['profit_per_365_days'] = data_df['profit'] / header_df['days'].iloc[0] * 365\n",
    "    data_df['profit_per_30_days_percent'] = data_df['profit'] / header_df['days'].iloc[0] * 30 / data_df['initial_deposit']\n",
    "    data_df['profit_per_365_days_percent'] = data_df['profit'] / header_df['days'].iloc[0] * 365 / data_df['initial_deposit']\n",
    "    data_df['trades_per_30_days'] = data_df['trades'] / header_df['days'].iloc[0] * 30\n",
    "    \n",
    "    data_df['filename'] = optcache_filename\n",
    "    data_df['symbol'] = header_df['symbol'].iloc[0]\n",
    "    data_df['expert_name'] = header_df['expert_name'].iloc[0]\n",
    "    data_df['date_from'] = header_df['date_from'].iloc[0]\n",
    "    data_df['date_to'] = header_df['date_to'].iloc[0]\n",
    "    data_df['days'] = (pd.to_datetime(header_df['date_to'].iloc[0]) - pd.to_datetime(header_df['date_from'].iloc[0])).days\n",
    "    data_df['months'] = (pd.to_datetime(header_df['date_to'].iloc[0]) - pd.to_datetime(header_df['date_from'].iloc[0])).days // 30\n",
    "    data_df['period'] = header_df['period'].iloc[0]\n",
    "    data_df['trade_deposit'] = header_df['trade_deposit'].iloc[0]\n",
    "    data_df['trade_currency'] = header_df['trade_currency'].iloc[0]\n",
    "    data_df['trade_leverage'] = header_df['trade_leverage'].iloc[0]\n",
    "    data_df['server'] = header_df['server'].iloc[0]\n",
    "    data_df['ticks_mode'] = header_df['ticks_mode'].iloc[0]\n",
    "    \n",
    "    data_df.fillna(0, inplace=True)\n",
    "\n",
    "    # filter data\n",
    "    report_data = data_df.copy()\n",
    "    for column, rule in filter.get('fields', {}).items():\n",
    "        if not rule.get('enabled', True):\n",
    "            continue\n",
    "        if not rule.get('range'):\n",
    "            continue\n",
    "        min_val, max_val = rule['range']\n",
    "        report_data = report_data[(report_data[column] >= min_val) & (report_data[column] <= max_val)]\n",
    "\n",
    "    report_data = report_data.sort_values(filter_rule.get('sort_by', []), ascending=filter_rule.get(\"sort_dir\", []))\n",
    "    if 'max_runs_count' in filter:\n",
    "        report_data = report_data.head(filter.get('max_runs_count'))\n",
    "\n",
    "    return report_data\n",
    "\n",
    "def CreateSetFile(optcache_filename: str, pass_number: int, output_dir: str = None, record_num: int = 1, total_records: int = 1) -> str:\n",
    "    \"\"\"\n",
    "    Create a .set file from optimization data for a specific pass.\n",
    "    \n",
    "    Args:\n",
    "        optcache_filename: Path to the .opt file\n",
    "        pass_number: Pass number to extract parameters from\n",
    "        output_dir: Output directory for .set file (default: same as opt file)\n",
    "        record_num: Record number in the report (for filename prefix)\n",
    "        total_records: Total number of records (to determine prefix width)\n",
    "    \n",
    "    Returns:\n",
    "        Path to created .set file or empty string if failed\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load header to get expert name and symbol\n",
    "    header_df = LoadHeaderFromFileToDF(optcache_filename)\n",
    "    if header_df.empty:\n",
    "        print(f\"Cannot load header from {optcache_filename}\")\n",
    "        return \"\"\n",
    "    \n",
    "    expert_name = header_df['expert_name'].iloc[0]\n",
    "    symbol = header_df['symbol'].iloc[0]\n",
    "    \n",
    "    # Load data to find the specific pass\n",
    "    data_file = Path(f'{optcache_filename}.Data.csv')\n",
    "    if not data_file.exists():\n",
    "        print(f\"File {data_file} does not exist\")\n",
    "        return \"\"\n",
    "    \n",
    "    data_df = pd.read_csv(data_file, sep=';', encoding='utf-16')\n",
    "    \n",
    "    # Find the pass\n",
    "    pass_data = data_df[data_df['Pass'] == pass_number]\n",
    "    if pass_data.empty:\n",
    "        print(f\"Pass {pass_number} not found in {data_file}\")\n",
    "        return \"\"\n",
    "    \n",
    "    # Get parameter columns - all columns after 'avgconloosers'\n",
    "    all_columns = list(data_df.columns)\n",
    "    try:\n",
    "        # Find the index of the last standard MetaTrader field\n",
    "        last_standard_field_idx = all_columns.index('avgconloosers')\n",
    "        # All columns after this are optimization parameters\n",
    "        param_columns = all_columns[last_standard_field_idx + 1:]\n",
    "    except ValueError:\n",
    "        # If 'avgconloosers' not found, fall back to 'Inp_' prefix\n",
    "        param_columns = [col for col in all_columns if col.startswith('Inp_')]\n",
    "    \n",
    "    if not param_columns:\n",
    "        print(f\"No input parameters found (columns after 'avgconloosers')\")\n",
    "        return \"\"\n",
    "    \n",
    "    # Create .set file content\n",
    "    set_content = [\n",
    "        \"; saved automatically on generation\",\n",
    "        \"; this file contains input parameters for testing/optimizing expert advisor\",\n",
    "        \";\"\n",
    "    ]\n",
    "    \n",
    "    # Add each parameter\n",
    "    pass_row = pass_data.iloc[0]\n",
    "    for param in param_columns:\n",
    "        value = pass_row[param]\n",
    "        \n",
    "        # Determine parameter type and format value\n",
    "        if isinstance(value, (int, np.integer)):\n",
    "            set_content.append(f\"{param}={int(value)}\")\n",
    "        elif isinstance(value, (float, np.floating)):\n",
    "            set_content.append(f\"{param}={value}\")\n",
    "        else:\n",
    "            set_content.append(f\"{param}={value}\")\n",
    "    \n",
    "    # Determine output path\n",
    "    if output_dir is None:\n",
    "        output_dir = Path(optcache_filename).parent\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Calculate prefix width based on total records\n",
    "    prefix_width = len(str(total_records))\n",
    "    \n",
    "    # Create .set filename with zero-padded prefix\n",
    "    num_prefix = str(record_num).zfill(prefix_width)\n",
    "    set_filename = output_dir / f\"{num_prefix}_{expert_name}.{symbol}.{pass_number}.set\"\n",
    "    \n",
    "    # Write .set file\n",
    "    try:\n",
    "        with open(set_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(set_content))\n",
    "        return str(set_filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing .set file: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildReportRowsMD(header_df: pd.DataFrame, data_df: pd.DataFrame, filter: dict) -> list:\n",
    "    \"\"\"Build markdown report with dynamic columns based on varying values\"\"\"\n",
    "    \n",
    "    def colorize(field_name, value, text):\n",
    "        rule = filter.get('fields', {}).get(field_name, {})\n",
    "\n",
    "        if not rule:\n",
    "            return text\n",
    "\n",
    "        color_ranges = rule.get('color_ranges', [])\n",
    "        if not color_ranges:\n",
    "            return text\n",
    "\n",
    "        for cr in color_ranges:\n",
    "            if value >= cr['range'][0] and value < cr['range'][1]:\n",
    "                return f'<span style=\"background-color:{cr[\"color\"]};\">{text}</span>'\n",
    "        return text\n",
    "\n",
    "    # Define all columns in desired order with their properties\n",
    "    # 'optional': True means column will be shown only if values vary\n",
    "    all_columns = [\n",
    "        {'field': '#', 'title': '#', 'optional': False},\n",
    "        {'field': 'symbol', 'title': 'Symbol', 'optional': False},\n",
    "        {'field': 'expert_name', 'title': 'Expert', 'optional': True},\n",
    "        {'field': 'period', 'title': 'TF', 'optional': True},\n",
    "        {'field': 'server', 'title': 'Server', 'optional': True},\n",
    "        {'field': 'trade_deposit', 'title': 'Deposit', 'optional': True},\n",
    "        {'field': 'ticks_mode', 'title': 'Ticks', 'optional': True},\n",
    "        {'field': 'pass_num', 'title': 'Pass', 'optional': False},\n",
    "        {'field': 'profit', 'title': 'Profit', 'optional': False},\n",
    "        {'field': 'profit_per_30_days_percent', 'title': \"<span title='Profit per 30 days, %'>30d,%</span>\", 'optional': False},\n",
    "        {'field': 'win_rate', 'title': \"<span title='Win Rate'>WR</span>\", 'optional': False},\n",
    "        {'field': 'custom_fitness', 'title': \"<span title='Custom Criterion'>CC</span>\", 'optional': False},\n",
    "        {'field': 'trades', 'title': 'Trades', 'optional': False},\n",
    "        {'field': 'trades_per_30_days', 'title': \"<span title='Trades per 30 days'>30d</span>\", 'optional': False},\n",
    "        {'field': 'reldrawdownpercnt_e', 'title': \"<span title='Equity Drawdown, %'>DD</span>\", 'optional': False},\n",
    "        {'field': 'profit_factor', 'title': \"<span title='Profit Factor'>PF</span>\", 'optional': False},\n",
    "        {'field': 'recovery_factor', 'title': \"<span title='Recovery Factor'>RF</span>\", 'optional': False},\n",
    "        {'field': 'sharpe_ratio', 'title': 'Sharpe', 'optional': False},\n",
    "        {'field': 'rank', 'title': 'Rank', 'optional': False},\n",
    "        {'field': 'comment', 'title': 'Comment', 'optional': False},\n",
    "    ]\n",
    "    \n",
    "    # Determine which columns to show\n",
    "    columns_to_show = []\n",
    "    for col in all_columns:\n",
    "        if col['optional']:\n",
    "            # Show only if field exists and has varying values\n",
    "            if col['field'] in data_df.columns and data_df[col['field']].nunique() > 1:\n",
    "                columns_to_show.append(col)\n",
    "        else:\n",
    "            columns_to_show.append(col)\n",
    "    \n",
    "    # Build dynamic header\n",
    "    header_parts = []\n",
    "    separator_parts = []\n",
    "    \n",
    "    for col in columns_to_show:\n",
    "        header_parts.append(col['title'])\n",
    "        separator_parts.append('-')\n",
    "    \n",
    "    data_report = [\n",
    "        '| ' + ' | '.join(header_parts) + ' |',\n",
    "        '| ' + ' | '.join(separator_parts) + ' |'\n",
    "    ]\n",
    "    \n",
    "    # Build dynamic row template parts\n",
    "    row_parts = []\n",
    "    for col in columns_to_show:\n",
    "        row_parts.append('{' + col['field'] + '}')\n",
    "    \n",
    "    row_template = '| ' + ' | '.join(row_parts) + ' |'\n",
    "    \n",
    "    data_df = data_df.sort_values(filter.get('sort_by', []), ascending=filter.get(\"sort_dir\", []))\n",
    "    for i, (_, data_row) in enumerate(data_df.iterrows(), 1):\n",
    "        row_data = {\n",
    "            '#': int(i),\n",
    "            'symbol': f\"<span title='{data_row['filename']}'>[{data_row['symbol']}]({data_row['filename']})</span>\",\n",
    "            'expert_name': str(data_row['expert_name']),\n",
    "            'period': str(data_row['period']),\n",
    "            'server': str(data_row['server']),\n",
    "            'trade_deposit': f\"{data_row['trade_deposit']:.0f}\",\n",
    "            'ticks_mode': str(data_row['ticks_mode']),\n",
    "            'pass_num': int(data_row['Pass']),\n",
    "            'profit': colorize('profit', data_row['profit'], f\"{data_row['profit']:,.0f}\".replace(',', ' ')),\n",
    "            'profit_per_30_days_percent': colorize('profit_per_30_days_percent', data_row['profit_per_30_days_percent'],\n",
    "                                                round(data_row['profit_per_30_days_percent'] * 100, 1)),\n",
    "            'win_rate': round(data_row['win_rate'] * 100, 1),\n",
    "            'custom_fitness': colorize('custom_fitness', data_row['custom_fitness'], round(data_row['custom_fitness'], 2)),\n",
    "            'trades': int(data_row['trades']),\n",
    "            'trades_per_30_days': round(data_row['trades_per_30_days'], 1),\n",
    "            'reldrawdownpercnt_e': colorize('reldrawdownpercnt_e', data_row['reldrawdownpercnt_e'],\n",
    "                                        round(data_row['reldrawdownpercnt_e'], 2)),\n",
    "            'profit_factor': round(data_row['profit_factor'], 2),\n",
    "            'recovery_factor': round(data_row['recovery_factor'], 2),\n",
    "            'sharpe_ratio': round(data_row['sharpe_ratio'], 2),\n",
    "            'rank': '☆☆☆☆☆',\n",
    "            'comment': ''\n",
    "        }\n",
    "        \n",
    "        data_report.append(row_template.format(**row_data))\n",
    "\n",
    "    return data_report\n",
    "\n",
    "def BuildReportRowsCSV(data_df: pd.DataFrame, header_df: pd.DataFrame, filter: dict) -> list:\n",
    "    \"\"\"Build CSV report with all fields\"\"\"\n",
    "    \n",
    "    data_report_csv = [\"num;filename;symbol;period;date_from;date_to;deposit;leverage;server;ticks_mode;pass_num;profit;profit_per_30_days_percent;profit_per_365_days_percent;win_rate;custom_fitness;trades;trades_per_30_days;reldrawdownpercnt_e;profit_factor;recovery_factor;sharpe_ratio\"]\n",
    "    row_template_csv = \"{i};{filename};{symbol};{period};{date_from};{date_to};{deposit};{leverage};{server};{ticks_mode};{pass_num};{profit};{profit_per_30_days_percent};{profit_per_365_days_percent};{win_rate};{custom_fitness};{trades};{trades_per_30_days};{reldrawdownpercnt_e};{profit_factor};{recovery_factor};{sharpe_ratio}\"\n",
    "\n",
    "    data_df = data_df.sort_values(filter.get('sort_by', []), ascending=filter.get(\"sort_dir\", []))\n",
    "    for i, (_, data_row) in enumerate(data_df.iterrows(), 1):\n",
    "        data_report_csv.append(row_template_csv.format(\n",
    "            i=int(i),\n",
    "            filename=data_row['filename'],\n",
    "            symbol=data_row['symbol'],\n",
    "            period=data_row['period'],\n",
    "            date_from=data_row['date_from'],\n",
    "            date_to=data_row['date_to'],\n",
    "            deposit=data_row['trade_deposit'],\n",
    "            leverage=data_row['trade_leverage'],\n",
    "            server=data_row['server'],\n",
    "            ticks_mode=data_row['ticks_mode'],\n",
    "            \n",
    "            pass_num=int(data_row['Pass']),\n",
    "            profit=data_row['profit'],\n",
    "            profit_per_30_days_percent=round(data_row['profit_per_30_days_percent'] * 100, 1),\n",
    "            profit_per_365_days_percent=round(data_row['profit_per_365_days_percent'] * 100, 1),\n",
    "            win_rate=round(data_row['win_rate'] * 100, 1),\n",
    "            custom_fitness=round(data_row['custom_fitness'], 2),\n",
    "            trades=int(data_row['trades']),\n",
    "            trades_per_30_days=round(data_row['trades_per_30_days'], 1),\n",
    "            reldrawdownpercnt_e=round(data_row['reldrawdownpercnt_e'], 2),\n",
    "            profit_factor=round(data_row['profit_factor'], 2),\n",
    "            recovery_factor=round(data_row['recovery_factor'], 2),\n",
    "            sharpe_ratio=round(data_row['sharpe_ratio'], 2)\n",
    "        ))\n",
    "    \n",
    "    return data_report_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Сортировка и вывод топ 5 результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD report saved: DSRBR-MT5-Bot_Tickmill-Live_21sym.md\n",
      "\n",
      "Creating .set files in set_files/...\n",
      "Created 80 .set files\n",
      "Created 80 .set files\n"
     ]
    }
   ],
   "source": [
    "dir = Path('csv')\n",
    "set_output_dir = Path('set_files')\n",
    "\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "report_md = []\n",
    "report_cvs = [\"num;filename;symbol;period;date_from;date_to;deposit;leverage;server;ticks_mode;pass_num;profit;profit_per_30_days_percent;profit_per_365_days_percent;win_rate;custom_fitness;trades;trades_per_30_days;reldrawdownpercnt_e;profit_factor;recovery_factor;sharpe_ratio\"]\n",
    "\n",
    "opt_files = sorted(dir.glob(\"*.opt\"))\n",
    "if not opt_files:\n",
    "    print(f\"No .opt files found in {dir}\")\n",
    "\n",
    "# build combined dataframe from all .opt files\n",
    "full_df = pd.DataFrame()\n",
    "for opt_file in opt_files:\n",
    "    opt_df = BuildReportDF(opt_file, filter_rule)\n",
    "    if not opt_df.empty:\n",
    "        full_df = pd.concat([full_df, opt_df], ignore_index=True)\n",
    "\n",
    "# load header from the first .opt file\n",
    "header_df = LoadHeaderFromFileToDF(opt_files[0])\n",
    "\n",
    "# Get report parameters for filename\n",
    "expert_name = header_df['expert_name'].iloc[0] if not header_df.empty else 'Unknown'\n",
    "server = header_df['server'].iloc[0] if not header_df.empty else 'Unknown'\n",
    "symbols_count = full_df['symbol'].nunique() if not full_df.empty else 0\n",
    "\n",
    "# Generate report filename\n",
    "report_filename = f\"{expert_name}_{server}_{symbols_count}sym.md\"\n",
    "\n",
    "# build MD-report\n",
    "report_header = BuildHeaderReport(header_df, full_df)\n",
    "report_data = BuildReportRowsMD(header_df, full_df, filter_rule)\n",
    "report_md = report_header + [''] + report_data\n",
    "\n",
    "# Save MD report\n",
    "with open(report_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in report_md:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"MD report saved: {report_filename}\")\n",
    "\n",
    "# Create .set files for all records in the report\n",
    "if not full_df.empty:\n",
    "    set_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Sort full_df the same way as in the report\n",
    "    sorted_df = full_df.sort_values(filter_rule.get('sort_by', []), ascending=filter_rule.get(\"sort_dir\", []))\n",
    "    \n",
    "    total_records = len(sorted_df)\n",
    "    print(f\"\\nCreating .set files in {set_output_dir}/...\")\n",
    "    created_count = 0\n",
    "    \n",
    "    for idx, row in sorted_df.iterrows():\n",
    "        opt_filename = row['filename']\n",
    "        pass_num = int(row['Pass'])\n",
    "        record_num = created_count + 1  # 1-based numbering\n",
    "        \n",
    "        set_file = CreateSetFile(\n",
    "            opt_filename, \n",
    "            pass_num, \n",
    "            output_dir=str(set_output_dir),\n",
    "            record_num=record_num,\n",
    "            total_records=total_records\n",
    "        )\n",
    "        if set_file:\n",
    "            created_count += 1\n",
    "    \n",
    "    print(f\"Created {created_count} .set files\")\n",
    "\n",
    "# report_csv = BuildReportRowsCSV(full_df, header_df, filter_rule)\n",
    "# with open(\"optcache_report.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     for line in report_csv:\n",
    "#         f.write(line + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
